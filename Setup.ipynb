{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5df84359-a370-47a6-8183-814630203762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Fetching data from CoinGecko API...\n",
      "✅ Fetched 250 rows from API.\n",
      "🔍 Running Data Quality Checks...\n",
      "📊 Checking for missing values (nulls)...\n",
      "⚠️ Total missing values across all columns: 342\n",
      "🔎 Missing values by column:\n",
      "high_24h                              1\n",
      "low_24h                               1\n",
      "price_change_24h                      1\n",
      "price_change_percentage_24h           1\n",
      "market_cap_change_24h                 1\n",
      "market_cap_change_percentage_24h      1\n",
      "max_supply                          118\n",
      "roi                                 218\n",
      "dtype: int64\n",
      "\n",
      "📊 Checking for negative values in numeric columns...\n",
      "✅ Column 'current_price' has no negative values.\n",
      "✅ Column 'market_cap' has no negative values.\n",
      "✅ Column 'total_volume' has no negative values.\n",
      "✅ Column 'ath' has no negative values.\n",
      "✅ Column 'atl' has no negative values.\n",
      "\n",
      "📊 Checking for duplicate IDs...\n",
      "✅ No duplicate IDs detected.\n",
      "\n",
      "📊 Checking for extreme price changes...\n",
      "✅ No extreme price changes detected.\n",
      "\n",
      "📊 Checking for invalid data types...\n",
      "✅ Column 'id' has valid data types.\n",
      "✅ Column 'symbol' has valid data types.\n",
      "✅ Column 'name' has valid data types.\n",
      "✅ Column 'image' has valid data types.\n",
      "✅ Column 'current_price' has valid data types.\n",
      "✅ Column 'market_cap' has valid data types.\n",
      "✅ Column 'market_cap_rank' has valid data types.\n",
      "✅ Column 'fully_diluted_valuation' has valid data types.\n",
      "✅ Column 'total_volume' has valid data types.\n",
      "✅ Column 'high_24h' has valid data types.\n",
      "✅ Column 'low_24h' has valid data types.\n",
      "✅ Column 'price_change_24h' has valid data types.\n",
      "✅ Column 'price_change_percentage_24h' has valid data types.\n",
      "✅ Column 'market_cap_change_24h' has valid data types.\n",
      "✅ Column 'market_cap_change_percentage_24h' has valid data types.\n",
      "✅ Column 'circulating_supply' has valid data types.\n",
      "✅ Column 'total_supply' has valid data types.\n",
      "✅ Column 'max_supply' has valid data types.\n",
      "✅ Column 'ath' has valid data types.\n",
      "✅ Column 'ath_change_percentage' has valid data types.\n",
      "✅ Column 'ath_date' has valid data types.\n",
      "✅ Column 'atl' has valid data types.\n",
      "✅ Column 'atl_change_percentage' has valid data types.\n",
      "✅ Column 'atl_date' has valid data types.\n",
      "✅ Column 'roi' has valid data types.\n",
      "✅ Column 'last_updated' has valid data types.\n",
      "\n",
      "📊 Checking for unreasonable values...\n",
      "⚠️ Found 3 unreasonable 'current_price' values.\n",
      "\n",
      "📊 Checking for invalid date formats...\n",
      "✅ Column 'ath_date' has valid date formats.\n",
      "✅ Column 'atl_date' has valid date formats.\n",
      "✅ Column 'last_updated' has valid date formats.\n",
      "\n",
      "🔍 Data Quality Check Results:\n",
      "❌ One or more checks failed. Please review the issues above.\n",
      "⚠️ Data failed quality checks.\n",
      "🔄 Proceeding to data normalization...\n",
      "🔄 Starting data normalization...\n",
      "📊 Dropping rows with missing values in important columns: ['current_price', 'market_cap', 'total_volume']\n",
      "✅ Remaining rows after dropping: 250\n",
      "\n",
      "📊 Handling missing values in less important columns...\n",
      "  - Filling missing values in column 'max_supply' with: 0\n",
      "  - Filling missing values in column 'roi' with: None\n",
      "\n",
      "📊 Removing unreasonable values...\n",
      "✅ Removed 3 rows with unreasonable 'current_price' values.\n",
      "✅ Removed 0 rows with negative 'market_cap' values.\n",
      "\n",
      "📊 Normalizing data types...\n",
      "✅ Normalized column 'id' to type <class 'str'>.\n",
      "✅ Normalized column 'symbol' to type <class 'str'>.\n",
      "✅ Normalized column 'name' to type <class 'str'>.\n",
      "✅ Normalized column 'image' to type <class 'str'>.\n",
      "✅ Normalized column 'current_price' to type <class 'float'>.\n",
      "✅ Normalized column 'market_cap' to type <class 'float'>.\n",
      "✅ Normalized column 'market_cap_rank' to type <class 'float'>.\n",
      "✅ Normalized column 'fully_diluted_valuation' to type <class 'float'>.\n",
      "✅ Normalized column 'total_volume' to type <class 'float'>.\n",
      "✅ Normalized column 'high_24h' to type <class 'float'>.\n",
      "✅ Normalized column 'low_24h' to type <class 'float'>.\n",
      "✅ Normalized column 'price_change_24h' to type <class 'float'>.\n",
      "✅ Normalized column 'price_change_percentage_24h' to type <class 'float'>.\n",
      "✅ Normalized column 'market_cap_change_24h' to type <class 'float'>.\n",
      "✅ Normalized column 'market_cap_change_percentage_24h' to type <class 'float'>.\n",
      "✅ Normalized column 'circulating_supply' to type <class 'float'>.\n",
      "✅ Normalized column 'total_supply' to type <class 'float'>.\n",
      "✅ Normalized column 'max_supply' to type <class 'float'>.\n",
      "✅ Normalized column 'ath' to type <class 'float'>.\n",
      "✅ Normalized column 'ath_change_percentage' to type <class 'float'>.\n",
      "✅ Normalized column 'ath_date' to type <class 'str'>.\n",
      "✅ Normalized column 'atl' to type <class 'float'>.\n",
      "✅ Normalized column 'atl_change_percentage' to type <class 'float'>.\n",
      "✅ Normalized column 'atl_date' to type <class 'str'>.\n",
      "✅ Normalized column 'roi' to type <class 'dict'>.\n",
      "✅ Normalized column 'last_updated' to type <class 'str'>.\n",
      "\n",
      "📊 Normalizing date formats...\n",
      "✅ Normalized column 'ath_date' to datetime format.\n",
      "✅ Normalized column 'atl_date' to datetime format.\n",
      "✅ Normalized column 'last_updated' to datetime format.\n",
      "\n",
      "🔍 Running post-normalization checks...\n",
      "⚠️ Data still contains 221 missing values after normalization.\n",
      "✅ Normalization complete. Final row count: 247\n",
      "✅ Data normalization complete.\n",
      "🔄 Saving data to the database... Status: failed_quality_check\n",
      "✅ Data saved successfully!\n",
      "✅ Data saved to database with status: failed_quality_check.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import json\n",
    "\n",
    "# Configure database connection\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"database\": \"crypto_db\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"123456\"\n",
    "}\n",
    "\n",
    "\n",
    "def fetch_crypto_data():\n",
    "    \"\"\"\n",
    "    Fetch data from CoinGecko API, perform quality checks, normalize data, and save to database.\n",
    "    If the quality check fails, the data is still normalized and saved with the status 'failed_quality_check'.\n",
    "    \"\"\"\n",
    "    print(\"🔄 Fetching data from CoinGecko API...\")\n",
    "    \n",
    "    url = \"https://api.coingecko.com/api/v3/coins/markets\"\n",
    "    params = {\n",
    "        \"vs_currency\": \"usd\",\n",
    "        \"order\": \"market_cap_desc\",\n",
    "        \"per_page\": 250,\n",
    "        \"page\": 1,\n",
    "        \"sparkline\": \"false\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        df = pd.DataFrame(response.json())\n",
    "        print(f\"✅ Fetched {len(df)} rows from API.\")\n",
    "\n",
    "        if run_quality_checks(df):\n",
    "            print(\"✅ Data passed quality checks.\")\n",
    "            quality_status = \"passed_quality_check\"\n",
    "        else:\n",
    "            print(\"⚠️ Data failed quality checks.\")\n",
    "            quality_status = \"failed_quality_check\" \n",
    "\n",
    "        print(\"🔄 Proceeding to data normalization...\")\n",
    "        df_normalized = normalize_data(df)\n",
    "        print(\"✅ Data normalization complete.\")\n",
    "\n",
    "        save_to_db(df_normalized, status=quality_status)\n",
    "        print(f\"✅ Data saved to database with status: {quality_status}.\")\n",
    "        \n",
    "        return df_normalized\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Error fetching data from API: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_to_db(df, status=None):\n",
    "    \"\"\"\n",
    "    Save data to PostgreSQL, updating if the coin already exists.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if 'roi' in df.columns:\n",
    "            df['roi'] = df['roi'].apply(lambda x: json.dumps(x) if isinstance(x, dict) else None)\n",
    "        \n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        cursor = conn.cursor()\n",
    "        print(f\"🔄 Saving data to the database... Status: {status}\")\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            try:\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO crypto_data (\n",
    "                        id, symbol, name, image, current_price, market_cap, market_cap_rank,\n",
    "                        fully_diluted_valuation, total_volume, high_24h, low_24h,\n",
    "                        price_change_24h, price_change_percentage_24h, market_cap_change_24h,\n",
    "                        market_cap_change_percentage_24h, circulating_supply, total_supply,\n",
    "                        max_supply, ath, ath_change_percentage, ath_date, atl,\n",
    "                        atl_change_percentage, atl_date, roi, last_updated\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    ON CONFLICT (id) DO UPDATE \n",
    "                    SET current_price = EXCLUDED.current_price,\n",
    "                        market_cap = EXCLUDED.market_cap,\n",
    "                        total_volume = EXCLUDED.total_volume,\n",
    "                        price_change_percentage_24h = EXCLUDED.price_change_percentage_24h\n",
    "                \"\"\", tuple(row[col] for col in df.columns))\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Failed to insert row: {row['id']} - Error: {e}\")\n",
    "                conn.rollback()  \n",
    "            else:\n",
    "                conn.commit()  \n",
    "\n",
    "        print(\"✅ Data saved successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to save data to database: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "\n",
    "def normalize_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize data from the DataFrame:\n",
    "    - Remove rows with missing values in important columns.\n",
    "    - Fill missing values in less important columns.\n",
    "    - Remove unreasonable values.\n",
    "    - Normalize data types if necessary.\n",
    "    - Handle date-time formatting.\n",
    "    \"\"\"\n",
    "    print(\"🔄 Starting data normalization...\")\n",
    "\n",
    "    # 1. Remove rows with missing values in important columns\n",
    "    important_columns = [\"current_price\", \"market_cap\", \"total_volume\"]\n",
    "    print(f\"📊 Dropping rows with missing values in important columns: {important_columns}\")\n",
    "    df = df.dropna(subset=important_columns)\n",
    "    print(f\"✅ Remaining rows after dropping: {len(df)}\")\n",
    "\n",
    "    # 2. Handle missing values in less important columns\n",
    "    print(\"\\n📊 Handling missing values in less important columns...\")\n",
    "    less_important_columns = {\n",
    "        \"max_supply\": 0,  \n",
    "        \"roi\": None     \n",
    "    }\n",
    "    for col, fill_value in less_important_columns.items():\n",
    "        if col in df.columns:\n",
    "            print(f\"  - Filling missing values in column '{col}' with: {fill_value}\")\n",
    "            if fill_value is None:\n",
    "                df[col] = df[col].apply(lambda x: x if pd.notnull(x) else None)\n",
    "            else:\n",
    "                df[col] = df[col].fillna(fill_value)\n",
    "\n",
    "    # 3. Remove unreasonable values\n",
    "    print(\"\\n📊 Removing unreasonable values...\")\n",
    "    if \"current_price\" in df.columns:\n",
    "        initial_rows = len(df)\n",
    "        df = df[(df[\"current_price\"] <= 1e6) & (df[\"current_price\"] >= 0.000001)]\n",
    "        print(f\"✅ Removed {initial_rows - len(df)} rows with unreasonable 'current_price' values.\")\n",
    "    if \"market_cap\" in df.columns:\n",
    "        initial_rows = len(df)\n",
    "        df = df[df[\"market_cap\"] >= 0]  \n",
    "        print(f\"✅ Removed {initial_rows - len(df)} rows with negative 'market_cap' values.\")\n",
    "\n",
    "    # 4. Normalize data types\n",
    "    print(\"\\n📊 Normalizing data types...\")\n",
    "    expected_types = {\n",
    "        \"id\": str,\n",
    "        \"symbol\": str,\n",
    "        \"name\": str,\n",
    "        \"image\": str,\n",
    "        \"current_price\": float,\n",
    "        \"market_cap\": float,\n",
    "        \"market_cap_rank\": float,\n",
    "        \"fully_diluted_valuation\": float,\n",
    "        \"total_volume\": float,\n",
    "        \"high_24h\": float,\n",
    "        \"low_24h\": float,\n",
    "        \"price_change_24h\": float,\n",
    "        \"price_change_percentage_24h\": float,\n",
    "        \"market_cap_change_24h\": float,\n",
    "        \"market_cap_change_percentage_24h\": float,\n",
    "        \"circulating_supply\": float,\n",
    "        \"total_supply\": float,\n",
    "        \"max_supply\": float,\n",
    "        \"ath\": float,\n",
    "        \"ath_change_percentage\": float,\n",
    "        \"ath_date\": str,\n",
    "        \"atl\": float,\n",
    "        \"atl_change_percentage\": float,\n",
    "        \"atl_date\": str,\n",
    "        \"roi\": dict,\n",
    "        \"last_updated\": str\n",
    "    }\n",
    "    for col, expected_type in expected_types.items():\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                if expected_type == float:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')  \n",
    "                elif expected_type == str:\n",
    "                    df[col] = df[col].astype(str)  \n",
    "                elif expected_type == dict:\n",
    "                    df[col] = df[col].apply(lambda x: x if isinstance(x, dict) else None)  \n",
    "                print(f\"✅ Normalized column '{col}' to type {expected_type}.\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error normalizing column '{col}': {e}\")\n",
    "\n",
    "    # 5. Handle date-time formatting\n",
    "    print(\"\\n📊 Normalizing date formats...\")\n",
    "    date_columns = [\"ath_date\", \"atl_date\", \"last_updated\"]\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                df[col] = pd.to_datetime(df[col], errors='coerce')  \n",
    "                print(f\"✅ Normalized column '{col}' to datetime format.\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error normalizing date column '{col}': {e}\")\n",
    "\n",
    "    # 6. Post-normalization checks\n",
    "    print(\"\\n🔍 Running post-normalization checks...\")\n",
    "    total_nulls = df.isnull().sum().sum()\n",
    "    if total_nulls > 0:\n",
    "        print(f\"⚠️ Data still contains {total_nulls} missing values after normalization.\")\n",
    "    else:\n",
    "        print(\"✅ No missing values detected after normalization.\")\n",
    "\n",
    "    print(f\"✅ Normalization complete. Final row count: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "def run_quality_checks(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Perform data quality checks and print detailed information.\n",
    "    \"\"\"\n",
    "    print(\"🔍 Running Data Quality Checks...\")\n",
    "    passed = True  \n",
    "\n",
    "    # 1. Check for missing values across the entire DataFrame\n",
    "    print(\"📊 Checking for missing values (nulls)...\")\n",
    "    null_summary = df.isnull().sum()\n",
    "    total_nulls = null_summary.sum()\n",
    "    if total_nulls > 0:\n",
    "        print(f\"⚠️ Total missing values across all columns: {total_nulls}\")\n",
    "        print(\"🔎 Missing values by column:\")\n",
    "        print(null_summary[null_summary > 0])\n",
    "        passed = False\n",
    "    else:\n",
    "        print(\"✅ No missing values detected.\")\n",
    "\n",
    "    # 2. Check for negative values in numeric columns\n",
    "    print(\"\\n📊 Checking for negative values in numeric columns...\")\n",
    "    numeric_columns = [\"current_price\", \"market_cap\", \"total_volume\", \"ath\", \"atl\"]\n",
    "    for col in numeric_columns:\n",
    "        if col in df.columns:\n",
    "            negative_count = (df[col] < 0).sum()\n",
    "            if negative_count > 0:\n",
    "                print(f\"❌ Column '{col}' has {negative_count} negative values!\")\n",
    "                passed = False\n",
    "            else:\n",
    "                print(f\"✅ Column '{col}' has no negative values.\")\n",
    "\n",
    "    # 3. Check for duplicate IDs\n",
    "    print(\"\\n📊 Checking for duplicate IDs...\")\n",
    "    duplicate_count = df.duplicated(subset=[\"id\"]).sum()\n",
    "    if duplicate_count > 0:\n",
    "        print(f\"⚠️ Found {duplicate_count} duplicate IDs.\")\n",
    "        passed = False\n",
    "    else:\n",
    "        print(\"✅ No duplicate IDs detected.\")\n",
    "\n",
    "    # 4. Check for extreme price changes\n",
    "    print(\"\\n📊 Checking for extreme price changes...\")\n",
    "    if \"price_change_percentage_24h\" in df.columns:\n",
    "        extreme_changes = (df[\"price_change_percentage_24h\"].abs() > 1000).sum()\n",
    "        if extreme_changes > 0:\n",
    "            print(f\"⚠️ Found {extreme_changes} extreme price change(s) (>1000%).\")\n",
    "            passed = False\n",
    "        else:\n",
    "            print(\"✅ No extreme price changes detected.\")\n",
    "\n",
    "    # 5. Check for invalid data types\n",
    "    print(\"\\n📊 Checking for invalid data types...\")\n",
    "    expected_types = {\n",
    "        \"id\": str,\n",
    "        \"symbol\": str,\n",
    "        \"name\": str,\n",
    "        \"image\": str,\n",
    "        \"current_price\": (float, int),\n",
    "        \"market_cap\": (float, int),\n",
    "        \"market_cap_rank\": (float, int),\n",
    "        \"fully_diluted_valuation\": (float, int),\n",
    "        \"total_volume\": (float, int),\n",
    "        \"high_24h\": (float, int),\n",
    "        \"low_24h\": (float, int),\n",
    "        \"price_change_24h\": (float, int),\n",
    "        \"price_change_percentage_24h\": (float, int),\n",
    "        \"market_cap_change_24h\": (float, int),\n",
    "        \"market_cap_change_percentage_24h\": (float, int),\n",
    "        \"circulating_supply\": (float, int),\n",
    "        \"total_supply\": (float, int),\n",
    "        \"max_supply\": (float, int),\n",
    "        \"ath\": (float, int),\n",
    "        \"ath_change_percentage\": (float, int),\n",
    "        \"ath_date\": str,\n",
    "        \"atl\": (float, int),\n",
    "        \"atl_change_percentage\": (float, int),\n",
    "        \"atl_date\": str,\n",
    "        \"roi\": (dict, type(None)), \n",
    "        \"last_updated\": str\n",
    "    }\n",
    "    for col, expected_type in expected_types.items():\n",
    "        if col in df.columns:\n",
    "            invalid_type_count = (~df[col].apply(lambda x: isinstance(x, expected_type))).sum()\n",
    "            if invalid_type_count > 0:\n",
    "                print(f\"❌ Column '{col}' has {invalid_type_count} invalid data type(s).\")\n",
    "                passed = False\n",
    "            else:\n",
    "                print(f\"✅ Column '{col}' has valid data types.\")\n",
    "\n",
    "    # 6. Check for unreasonable values (e.g., extremely large or small values)\n",
    "    print(\"\\n📊 Checking for unreasonable values...\")\n",
    "    if \"current_price\" in df.columns:\n",
    "        unreasonable_prices = ((df[\"current_price\"] > 1e6) | (df[\"current_price\"] < 0.000001)).sum()\n",
    "        if unreasonable_prices > 0:\n",
    "            print(f\"⚠️ Found {unreasonable_prices} unreasonable 'current_price' values.\")\n",
    "            passed = False\n",
    "        else:\n",
    "            print(\"✅ All 'current_price' values are within a reasonable range.\")\n",
    "\n",
    "    # 7. Check for invalid date formats\n",
    "    print(\"\\n📊 Checking for invalid date formats...\")\n",
    "    date_columns = [\"ath_date\", \"atl_date\", \"last_updated\"]\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                pd.to_datetime(df[col], errors='coerce')  \n",
    "                print(f\"✅ Column '{col}' has valid date formats.\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Column '{col}' has invalid date formats. Error: {e}\")\n",
    "                passed = False\n",
    "\n",
    "    # Check results\n",
    "    print(\"\\n🔍 Data Quality Check Results:\")\n",
    "    if passed:\n",
    "        print(\"✅ All checks passed successfully!\")\n",
    "    else:\n",
    "        print(\"❌ One or more checks failed. Please review the issues above.\")\n",
    "\n",
    "    return passed\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_crypto_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1984825d-2b37-48c7-bf68-4f68be070262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_venv)",
   "language": "python",
   "name": "my_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
